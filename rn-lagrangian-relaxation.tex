\documentclass{article}
\pagestyle{plain}
\setlength\textwidth{266.0pt}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{subfigure}
\usepackage{caption}
\usepackage{bm}
\usepackage{array}
\usepackage{multirow}
\usepackage[paperwidth=185mm,paperheight=260mm,text={148mm,220mm},left=21mm,top=25.5mm]{geometry}
\usepackage[round]{natbib}
\usepackage{booktabs}
\usepackage{algorithm,algpseudocode,amsmath}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=blue]{hyperref}
\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}  
\usepackage{pdflscape}
 \newtheorem{thm}{Theorem}
\newtheorem{pro}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{alg}{Algorithm}
\newtheorem{ass}{Assumption}
\newtheorem{coro}{Corollary}
\newtheorem{defin}{Definition}
\newtheorem{ob}{Observation}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
%\newtheorem{proof}{Proof}
\usetikzlibrary{arrows,shapes,chains}  
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm  
\title {Review Notebook: Lagrangian Relaxation}
\author{CO2GENERATOR} 
\begin {document}
\maketitle 
\allowdisplaybreaks[4]

\section{Lagrangian Relaxation}
 
Consider the following linear integer programming problem(ILP),
\begin{align}
	(\textit{ILP}) \min \quad & \bm{c}^T\bm{x} \\
	s.t. \quad & \left\{\begin{aligned}
	& \bm{A}\bm{x} \leq \bm{b} \\
	& \bm{D}\bm{x} \leq \bm{d} \\
	& \bm{x} \in \mathbb{Z}^n
	\end{aligned} \right.
\end{align}
in which $\bm{D} \bm{x} \leq \bm{d}$ is $m$ constraints. Let $\bm{X}= \left\{\bm{x} \in \mathbb{R}^n \ | \ \bm{A}\bm{x} \leq \bm{b}\right\}$, $Conv(\bm{X}) = \left\{\bm{x} \in \mathbb{Z}^n \ | \ \bm{A}\bm{x} \leq \bm{b}\right\}$, and $\bm{u} = (u_1, ..., u_m)^T \in \mathbb{R}_+^m$, then the following problem
\begin{equation}
	 d(\bm{u}) = \min_{\bm{x} \in \bm{X}} \quad \mathcal{L}(\bm{x}, \bm{u}) := \bm{c}^T\bm{x} + \bm{u}^T(\bm{D}\bm{x} - \bm{d}) 
\end{equation}
 is defined as \textit{Lagrangian relaxation}, $\bm{u}$ is so called the \textit{Lagrangian multipliers}. And 
 \begin{equation}
 	(\textit{LD}) \max_{\bm{u} \in \mathbb{R}_+^m}d(\bm{u})
 \end{equation}
 is the \textit{Lagrangian Dual Problem}.
 
 \begin{thm} 
 	(Weak Duality) The following equation holds,
 	\begin{equation}
 		v(LD) \leq v(ILP)
 	\end{equation}
 \end{thm}

\begin{proof}
	For any $\bm{u} \in \mathbb{R}_+^m$ and $\bm{x} \in \bm{X}$ that $\bm{Dx} \leq \bm{d}$, we have
	\begin{equation}
		\bm{c}^T \bm{x} + \bm{u}^T (\bm{Dx} - \bm{d}) \leq \bm{c}^T\bm{x}
	\end{equation}
	Therefore,
	\begin{equation}
		v(LD) = \max_{\bm{u} \in \mathbb{R}_+^m} d(\bm{u}) \leq \min \left\{\bm{c}^T\bm{x} \ | \ \bm{D}\bm{x} \leq \bm{d}, \bm{x} \in \bm{X}\right\} = v(ILP)
	\end{equation}
\end{proof}

\begin{thm}
	(Strong Duality) Let $\bm{u}^* \in \mathbb{R}_+^m$, if the following conditions holds,
	\begin{enumerate}
		\item $\bm{x}^* \in \bm{X}$ is the optimal solution of problem \textit{LD}.
		\item $\bm{x}^*$ is the feasible solution of problem \textit{ILP}.
		\item the complementary slackness conditions holds, i.e. $\bm{u}^{*T}(\bm{D}\bm{x}^* - \bm{d}) = 0$.
	\end{enumerate} 
	then $\bm{x}^*$ is the optimal solution to \textit{ILP} and $v(ILP) = v(LD)$.
\end{thm}

\begin{proof}
	With condition 1 and 3, we have 
	\begin{equation}
		v(LD) \geq d(\bm{u}^*) = \bm{c}^T\bm{x}^* + \bm{u}^{*T}(\bm{D}\bm{x}^*-\bm{d}) = \bm{c}^T\bm{x}^*
	\end{equation}
	And with condition 2, 
	\begin{equation}
		\bm{c}^T\bm{x}^* \geq v(ILP)
	\end{equation}
	So,
	\begin{equation}
		v(LD) \geq \bm{c}^T\bm{x}^* \geq v(ILP)
	\end{equation}
	And we have already known the \textit{Weak Duality} holds,
	\begin{equation}
		v(ILP) \geq v(LD)
	\end{equation}
	Therefore,
	\begin{equation}
		v(ILP) = v(LD)
	\end{equation}
	and $\bm{x}^*$ is the optimal solution to problem \textit{ILP}.
\end{proof}


\section{Continuous Relaxation and Dual Relaxation}
 
 Consider the following general integer programming problem,
 \begin{align}
 	(\textit{IP}) \min \quad & f(\bm{x}) \\
	s.t. \quad & \left\{ 
	\begin{aligned}
	& g(\bm{x}) \leq \bm{b} \\
	& \bm{x} \in \bm{X} 
	\end{aligned} \right.
 \end{align} 
 where $\bm{X}$ is a finitely integers set and $\bm{b}$ is $m \times 1$ column vector. By introducing the Lagrangian multipliers $\bm{\lambda} \in \mathbb{R}_+^m$, the Lagrangian function can be constructed as, 
 \begin{align}
 \mathcal{L}(\bm{x}, \bm{\lambda}) = f(\bm{x}) + \bm{\lambda}^T(g(\bm{x}) - \bm{b})
 \end{align}
 And name the following $d(\bm{\lambda})$ as dual function,
 \begin{equation}
 d(\bm{\lambda}) = \min_{\bm{x} \in \bm{X}} 	\mathcal{L}(\bm{x}, \bm{\lambda})
 \end{equation}
The Lagrangian dual problem of problem \textit{IP} is
 \begin{align}
	(DIP) \max_{\bm{\lambda} \in \mathbb{R}_+^m} \min_{\bm{x} \in \bm{X}} f(\bm{x}) + \bm{\lambda}^T(g(\bm{x}) - \bm{b})
 \end{align}
 
 \begin{thm}
 	The dual function $d(\bm{\lambda})$ is a piecewise linear concave function on $\mathbb{R}_+^m$.
 \end{thm}
 
 \begin{proof}
 	For any $\bm{\lambda} \in \mathbb{R}_+^n$,
 	\begin{align}
 	d(\bm{\lambda}) = \min_{\bm{x} \in \bm{X}} f(\bm{x}) + \bm{\lambda}^T(g(\bm{x}) - \bm{b}) 
 	\end{align}
 	Since $\bm{X}$ is a finitely integers set, assume $\bm{X} = \left\{\bm{x}^i, i = 1, ..., N\right\}$, then
 	\begin{align}
 	d(\bm{\lambda}) = \min \left\{f(\bm{x}^i) + \bm{\lambda}^T(g(\bm{x}^i) - \bm{b}), i = 1, ..., N \right\}
 	\end{align}
 	It is the minimum of the finite number of linear functions of $\lambda$. Therefore, $d(\bm{\lambda})$ is a piecewise linear concave function.
 \end{proof}
 
\begin{remark}
	This theorem provides a good property for solving some problems which has special structure. For an instance, the problem is separable, then we can efficiently solve the Lagrangian relaxation problem. 
\end{remark} 
 
 The continuous relaxation of problem \textit{IP} is,
 \begin{align}
  	(\textit{CIP}) \min \quad & f(\bm{x}) \\
	 s.t. \quad & \left\{ 
	 \begin{aligned}
	 & g(\bm{x}) \leq \bm{b} \\
	 & \bm{x} \in Conv(\bm{X}) 
	 \end{aligned} \right.
 \end{align}
 where $Conv(\bm{X})$ is the convex hull of $\bm{X}$.

\begin{thm}
	The lower bound obtained by Lagrangian dual problem can always be better than continuous relaxation problem, i.e.
	\begin{equation} 
		v(DIP) \geq v(CIP)
	\end{equation}
\end{thm}

\begin{proof}
	Since $\bm{X} \subseteq Conv(\bm{X})$ and the strong duality theorem holds for convex optimization problems,
	\begin{align}
		v(DIP) & = \max_{\bm{\lambda} \in \mathbb{R}_+^m} \min_{\bm{x} \in \bm{X}} \mathcal{L}(\bm{x}, \bm{\lambda}) \\
		& \geq \max_{\bm{\lambda} \in \mathbb{R}_+^m} \min_{\bm{x} \in Conv(\bm{X})} \mathcal{L}(\bm{x}, \bm{\lambda}) \\
		& = v(CIP)
	\end{align}
	Therefore, $v(DIP) \geq v(CIP)$.
\end{proof}

In particular, for linear integer programming(ILP),
\begin{align}
	\textit{(ILP)} \min \quad & \bm{c}^T\bm{x} \\
	 s.t. \quad & \left\{ 
	\begin{aligned}
	& \bm{D}\bm{x} \leq \bm{d} \\
	& \bm{x} \in \bm{X}
	\end{aligned} \right.
\end{align}
one of the continuous relaxation can be,
\begin{align}
	\textit{(CILP)} \min \quad & \bm{c}^T\bm{x} \\
	s.t. \quad & \left\{ 
	\begin{aligned}
	& \bm{D}\bm{x} \leq \bm{d} \\
	& \bm{x} \in Conv(\bm{X})
	\end{aligned} \right.
\end{align}

\begin{thm}
	For linear integer programming, the lower bound obtained by Lagrangian dual problem is the same as continuous relaxation, i.e.
	\begin{equation}
		v(DILP) = v(CILP)
	\end{equation}
\end{thm}
\begin{proof}
	Assume $\bm{X} = \left\{\bm{x}^1, ..., \bm{x}^N\right\}$, then we have that
	\begin{align}
		v(DILP) &= \max_{\bm{\lambda} \geq 0} d(\lambda) \\
		&= \max_{\bm{\lambda} \geq 0} \min_{\bm{x} \in \bm{X}} \bm{c}^T\bm{x} + \bm{\lambda}^T(\bm{Dx} - \bm{d}) \\
		&= \max_{\bm{\lambda} \geq 0} \min_{i = 1 , ... , N} \bm{c}^T\bm{x}^i + \bm{\lambda}^T(\bm{D}\bm{x}^i - \bm{d}) \\
		& = \max \quad \eta \\
		& \quad \ \begin{aligned}
		s.t. \quad& \bm{c}^T\bm{x}^i + \bm{\lambda}^T(\bm{D}\bm{x}^i - \bm{d}) \geq \eta , i = 1, ..., N\\
		& \bm{\lambda} \geq 0, \eta \in \mathbb{R}
		\end{aligned} 
	\end{align}
	As we can see, problem (29)-(30) is a linear programming problem which has enormous number of constraints. And its dual problem is,
	\begin{align}
	\min \quad & \sum_{i=1}^{N}\mu_i \bm{c}^T\bm{x}^i \\
	s.t. \quad & \sum_{i=1}^{N}\mu_i(\bm{D}\bm{x}^i - \bm{d}) \leq 0 \\
	& \sum_{i=1}^{N}\mu_i = 1, \mu_i \geq 0
	\end{align}
	Let $\bm{x}^\prime = \sum_{i=1}^{N} \mu_i \bm{x}^i$, since $\sum_{i=1}^{N} \mu_i = 1, \mu_i \geq 0$, so $\bm{x}^\prime$ is the convex combination of $\bm{x}^i, i =1, ..., N$. And problem (32)-(34) is equivalent to the following problem,
	\begin{equation}
		\min \left\{\bm{c}^T\bm{x}^\prime \ | \ \bm{D}\bm{x} \leq \bm{d}, \bm{x}^\prime \in Conv(\bm{X})\right\}
	\end{equation}
	And it definitely is problem \textit{CILP}. Since the strong duality holds for linear programming, it can be easily find that $v(DILP) = v(CILP)$.
\end{proof}

\begin{coro}
	Assume $\bm{X} = \left\{\bm{x} \in \mathbb{Z}^n \ | \ \bm{Ax} \leq \bm{b} \right\}$ and $\bar{\bm{X}} = \left\{ \bm{x} \in \mathbb{R}^n \ | \ \bm{Ax} \leq \bm{b} \right\}$. It can be easily find that for problem \textit{ILP}, its linear programming relaxation,
	\begin{align}
		(\textit{LP})\min \left\{\bm{c}^T\bm{x} \ | \ \bm{Dx} \leq \bm{d}, \bm{x} \in \bar{\bm{X}}\right\}
	\end{align}
	the following inequality holds,
	\begin{equation}
		v(DILP) = v(CIP) \geq v(LP)
	\end{equation}
\end{coro}
 
\section{Dual Search} 

For a general integer programming problem, except for the linear programming, 0-1 quadratic programming problem, etc., the Lagrangian dual problem
\begin{equation}
	\max_{\bm{\lambda} \geq 0} d(\bm{\lambda})
\end{equation}
has no closed formulation. But for any fixed $\bar{\bm{\lambda}} \geq 0$, we can obtain the value of $\bar{v} = d(\bar{\bm{\lambda}})$. Thus, the following three basic methods can be employed to find the optimal $\bm{\lambda}^*$.

\begin{itemize}
	\item Sub-gradient Search
	\item Outer-approximation Approach
	\item Bundle Method
\end{itemize}

\section{Conclusion}

I learned that the Lagrange relaxation can provide a better lower bound than linear programming relaxation. For the Lagrangian dual problem, we can use the dual search method to solve it. 

Although solving the Lagrangian dual problem may not be able to obtain the optimal solution of the primal problem, or even the feasible solution. However, when using global optimization methods such as branch and bound, to solve integer programming, the dual method can provide a better lower bound.

% \newpage
% \bibliographystyle{chicago}
% \bibliography{reference}
\end {document} 